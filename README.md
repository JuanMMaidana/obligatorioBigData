# An√°lisis Estrat√©gico para una Productora Cinematogr√°fica: Un Enfoque Basado en Datos üöÄ

**Autor:** Juan Maidana Agust√≠n Lorenzo
**Materia:** Big Data
**Fecha:** Julio 2025

---

## 1. Resumen del Proyecto

Este proyecto aborda el desaf√≠o de una productora cinematogr√°fica que busca transicionar de una toma de decisiones basada en la intuici√≥n a una estrategia fundamentada en evidencia emp√≠rica. El objetivo principal es desarrollar una plataforma de anal√≠tica de datos que permita optimizar el portafolio de inversiones, la selecci√≥n de proyectos y la estrategia de producci√≥n a trav√©s del an√°lisis de datos hist√≥ricos del mercado.

Para lograrlo, se dise√±√≥ e implement√≥ un Data Lake con una arquitectura de m√∫ltiples zonas (Raw, Refined, Curated) y se desarroll√≥ un pipeline de datos robusto y escalable utilizando **Apache Spark**. Este pipeline se encarga de la ingesta, limpieza, transformaci√≥n y agregaci√≥n de datos de m√°s de 45,000 pel√≠culas, culminando en la generaci√≥n de un conjunto de Indicadores Clave de Rendimiento (KPIs).

El an√°lisis de estos KPIs revel√≥ insights estrat√©gicos, entre los que destacan la identificaci√≥n de los g√©neros con mejor balance riesgo-recompensa, el descubrimiento de los rangos de presupuesto √≥ptimos para maximizar la rentabilidad y la cuantificaci√≥n de la tasa de √©xito real para diferentes tipos de producciones.

---

## 2. Arquitectura de la Soluci√≥n

La soluci√≥n se fundamenta en una arquitectura de **Data Lake** moderna, dise√±ada para garantizar la calidad, gobernanza y escalabilidad de los datos. La estructura l√≥gica se divide en tres zonas:

* **Zona Raw:** Punto de ingesta donde los datos se almacenan en su formato original. Act√∫a como una copia de seguridad persistente y auditable, desacoplando la ingesta de la transformaci√≥n.
* **Zona Refined:** El √°rea de procesamiento donde los datos son limpiados, validados, enriquecidos y unificados. Aqu√≠ reside la "fuente √∫nica de la verdad" del proyecto.
* **Zona Curated:** La capa final de consumo, donde se publican los productos de datos agregados (KPIs) en un formato optimizado (Parquet), listos para ser analizados y visualizados.

Este dise√±o multi-capa asegura la trazabilidad del dato y permite que los an√°lisis de negocio se realicen sobre un conjunto de datos curado y de alta confianza.

---

## 3. Metodolog√≠a y Pipeline de Datos

El procesamiento de datos se realiza a trav√©s de un pipeline automatizado y secuencial, orquestado en tres etapas principales:

1.  **Ingesta a la Zona Raw:** Los datos fuente (CSVs) son cargados y convertidos al formato columnar **Apache Parquet**, a√±adiendo metadatos de ingesta para su trazabilidad.
2.  **Procesamiento a la Zona Refined:** Se ejecutan las tareas intensivas de limpieza de datos, conversi√≥n de tipos, y el enriquecimiento a trav√©s de `joins`. En esta fase se calculan m√©tricas a nivel de pel√≠cula individual, como el ROI. Se aplica un riguroso filtro de calidad para trabajar √∫nicamente con registros que poseen datos financieros v√°lidos.
3.  **Agregaci√≥n a la Zona Curated:** Se calculan los KPIs finales y las agregaciones a nivel de negocio (ej. ROI mediano por g√©nero, tasa de √©xito, etc.), que servir√°n como base para todo el an√°lisis visual.

---

## 4. Hallazgos Clave y Resultados

El an√°lisis de los datos curados permiti√≥ extraer los siguientes insights estrat√©gicos, validados a trav√©s de un dashboard de visualizaci√≥n interactivo:

* **El Riesgo Var√≠a Significativamente entre G√©neros:** Aunque g√©neros como "Terror" y "Ciencia Ficci√≥n" presentan el potencial de ROI m√°s alto (demostrado por outliers en los Box Plots), su variabilidad es tambi√©n la mayor. En contraste, g√©neros como "Animaci√≥n" y "Aventura" ofrecen un **ROI mediano m√°s consistente y un menor riesgo**, perfil√°ndose como inversiones m√°s seguras.

* **La Tasa de √âxito es un Indicador de Riesgo Crucial:** Se determin√≥ que la probabilidad de que una pel√≠cula sea rentable (ROI > 0) es un indicador m√°s pragm√°tico que el ROI promedio. G√©neros con un ROI promedio alto pueden tener una tasa de √©xito inferior al 50%, lo que implica un alto riesgo de p√©rdida. Este an√°lisis permite a la productora construir un portafolio de inversiones m√°s balanceado.

* **Identificaci√≥n del "Sweet Spot" de Inversi√≥n:** El an√°lisis por rangos de presupuesto revel√≥ que las pel√≠culas de **presupuesto medio (entre $1M y $10M)** ofrecen el balance √≥ptimo entre rentabilidad y riesgo, presentando un ROI mediano robusto y una de las tasas de √©xito m√°s elevadas del estudio. Esto sugiere una estrategia de enfoque en este nicho en lugar de competir en el vol√°til mercado de los blockbusters.

* **Tendencias del Mercado a Largo Plazo:** El an√°lisis hist√≥rico muestra un incremento constante en los presupuestos promedio a lo largo de las d√©cadas, mientras que el ROI mediano no ha crecido al mismo ritmo. Esto indica una posible saturaci√≥n del mercado y una creciente necesidad de estrategias de producci√≥n eficientes y basadas en datos para mantener la rentabilidad.

---

## 5. Instrucciones de Uso

Para replicar este an√°lisis y explorar los resultados, siga los siguientes pasos:

1.  **Clonar el repositorio:**
    ```bash
    git clone [https://github.com/JuanMMaidana/obligatorioBigData.git](https://github.com/JuanMMaidana/obligatorioBigData.git)
    cd obligatorioBigData
    ```

2.  **Instalar dependencias:**
    (Aseg√∫rese de tener un entorno de Python 3 y Java 8+ configurado)
    ```bash
    pip install -r requirements.txt
    ```

3.  **Ejecutar el pipeline completo:**
    Este comando ejecutar√° las tres etapas del ETL y generar√° los datos en la carpeta `datalake/`.
    ```bash
    python run_pipeline.py
    ```

4.  **Generar las visualizaciones y el reporte:**
    Este comando leer√° los datos de la zona `curated` y crear√° el dashboard en `reports/charts/`.
    ```bash
    python visualize.py
    ```
    El dashboard principal se encontrar√° en `reports/charts/presentation.html`.

---

## 6. Tecnolog√≠as Utilizadas

* **Lenguaje de Programaci√≥n:** Python
* **Motor de Procesamiento:** Apache Spark
* **Librer√≠as Principales:** PySpark, Pandas, Matplotlib, Seaborn, Plotly
* **Formato de Almacenamiento:** Apache Parquet
* **Control de Versiones:** Git y GitHub